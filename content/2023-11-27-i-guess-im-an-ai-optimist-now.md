---

title: "I Guess I'm an AI Optimist Now"
created: 2023-11-27T16:45:11-06:00
date: 2023-11-27T17:12:17-0600
draft: false
slug: i-guess-im-an-ai-optimist-now
description: This is a short post, just read it.
tags: []
---

## TLDR

This is a short post, just read it.

## My Path to AI Optimist

I have had this conversation a couple times in the past month so I figured I should just solidify my thoughts and put them out there for the world.

I am now an AI{{<sup 1 >}} optimist.

What does this mean? For me, it means that I believe AI will act as a net positive for humanity rather than a net negative. Myself from earlier in 2023 would have been surprised to hear that I landed at this viewpoint, so why the shift? A few reasons:

1. AI is terrifying, and could result in serious decay of human civilization. But...
2. We don't know that yet, and it could also be a huge benefit. And...
3. Either way, I don't believe that worrying myself over hypothetical future disasters will do any good to stop a hypothetical disaster from occurring.

Ah ha - the pragmatic approach! I knew this felt familiar. Worrying about AI (i.e. being an AI pessimist) does nothing{{<sup 2>}} to benefit me or anyone around me. Therefore, worrying is unproductive. Of course it is still possible to be pessimistic about the future without actively worrying about it. But since there is no immediate evidence{{<sup 3>}} to indicate how the future will turn out (i.e. the future is ultimately unknowable), I am choosing to take an optimistic viewpoint because it feels better, and I don't see any concrete downside to being optimistic about it.

In addition to optimism being slightly more pragamatic in my view, I think there are some _potentially_ large upsides to AI tools in the future, such as:

1. Maybe we can stop busying ourselves with mundane shit tasks, like spending so much time communicating poorly over email.
2. Maybe we can actually improve our consumption of information by having AI summarize real facts for us.
3. Maybe we can free up our brains to focus on bigger issues that deserve our energy, rather than the trivialities that consume most of our lives.

I don't mean this to sound like everyone's life is trivial - that is not my point of view. However, for professional workers in a modern, industrialized economy, most of what we actually do on a daily basis is of little real value. Humans are extremely good to keeping ourselves busy (at least in America, my point of reference), but we aren't always good at making sure that our busyness is contributing to society. I would love it if my job was automated away and I could spend all my time working towards actually solving our climate crisis, or figuring out how to distribute resources equitably, or helping people live better lives.

Lastly, I'll note that in addition to this rosy view of things, AI also terrifies me. It is far beyond my individual comprehension, and that is scary. It also terrifies me to think that my professional skillset could be obsolete in 5 years. What exactly will I do for income? For a lot of my peers, I think this last point is the most salient fear they have. And yes, it is possible that we're heading towards The Greatest Of Depressions, but to reiterate my earlier points, I don't know what I'm supposed to do with that. Stand on a busy intersection with a sign that says "AI Bad, Human Good"?

I have never had someone reach out to me after reading a blog post to discuss, but I'd be super curious if someone has some well-reasoned arguments to convince me to be more pessimistic! You can just send me an email or something: eric [at] ericyd .com

---

{{<sup 1 >}}I'm using "AI" to describe tools that belong to the family of ML (Machine Learning) tools such as ChatGPT, Copilot, and Bard. ML is probably a more accurate term for these, but AI is how they are discussed in the popular discourse, so I follow suit.

{{<sup 2>}}Of course, worrying **can** be productive if I were prepared to put my worry to use by spurring myself into action. But I don't know what that action would look like, and for the other reasons outlined in this article, I'm not 100% convinced that the future will be bad anyway. Acting now to prevent an hypothetically-bad-but-ultimately-unknowable future seems kind of wrong.

{{<sup 3>}}I suppose this point is arguable, depending on your view of evidence. Certainly there are hints that mass unemployment may be coming (e.g. self-driving cars displacing drivers, LLMs displacing customer support teams, generative images displacing artists, generative code displacing programmers), but I would argue that we have yet to see any of these effects actually materialize. Unlike our current climate catastrophe which is unfolding in front of our eyes, I don't believe AI has significantly changed the way we do work. _Yet._
